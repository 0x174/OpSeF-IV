{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on 2_training and 3_prediction from StarDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tifffile as tif\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available,_draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "    \n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "# adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "limit_gpu_memory(0.8)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size.  \n",
    "Input images can either be two-dimensional (single-channel) or three-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processing pipeline from /home/trasse/github/OpSeF-IV/Train/Augment/my_runs/augment_settings_xl.pkl\n"
     ]
    }
   ],
   "source": [
    "main_folder = os.path.dirname(os.path.abspath(inspect.stack()[0][1])).replace(\"TrainStarDist\",\"Augment\")\n",
    "file_path = \"{}/my_runs/augment_settings_xl.pkl\".format(main_folder)\n",
    "infile = open(file_path,'rb')\n",
    "parameter = pickle.load(infile)\n",
    "print(\"Loading processing pipeline from\",file_path)\n",
    "infile.close()\n",
    "aug_sets,pre_defined_pipelines,data_main_GT,Datasets_Download = parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training 1\n",
    "trainModelSettings = {}\n",
    "trainModelSettings[\"root\"] = data_main_GT\n",
    "trainModelSettings[\"data\"] = \"DSB2018_FL_Nuc_Subset\"\n",
    "trainModelSettings[\"path\"] = os.path.join(trainModelSettings[\"root\"],trainModelSettings[\"data\"])\n",
    "trainModelSettings[\"basedir_StarDist_Train\"] = \"./models\"\n",
    "trainModelSettings[\"name\"] = 'Non_Augmented_Train_Small2'\n",
    "trainModelSettings[\"nrays\"] = 32\n",
    "trainModelSettings[\"epochs\"] = 4\n",
    "trainModelSettings[\"steps_per_epoch\"] = 100\n",
    "trainModelSettings[\"train_patch_size\"] = (256,256)\n",
    "trainModelSettings[\"unet_activation\"]= 'relu'\n",
    "\n",
    "run_list.append(trainModelSettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training 2\n",
    "trainModelSettings = {}\n",
    "trainModelSettings[\"root\"] = data_main_GT\n",
    "trainModelSettings[\"data\"] = \"DSB2018_FL_Nuc_Subset\"\n",
    "trainModelSettings[\"path\"] = os.path.join(trainModelSettings[\"root\"],trainModelSettings[\"data\"])\n",
    "trainModelSettings[\"basedir_StarDist_Train\"] = \"./models\"\n",
    "trainModelSettings[\"name\"] = 'Non_Augmented_Train_Medium2'\n",
    "trainModelSettings[\"nrays\"] = 32\n",
    "trainModelSettings[\"epochs\"] = 4\n",
    "trainModelSettings[\"steps_per_epoch\"] = 100\n",
    "trainModelSettings[\"train_patch_size\"] = (256,256)\n",
    "trainModelSettings[\"unet_activation\"]= 'relu'\n",
    "\n",
    "run_list.append(trainModelSettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_stardist(tms,n_channel):\n",
    "    # configures StarDist based on the standart settings and the trainModelSettings\n",
    "    n_rays = trainModelSettings[\"nrays\"]\n",
    "    use_gpu = False and gputools_available()\n",
    "    grid = (2,2)    \n",
    "    conf = Config2D (\n",
    "        n_rays       = trainModelSettings[\"nrays\"],\n",
    "        grid         = grid,\n",
    "        use_gpu      = use_gpu,\n",
    "        n_channel_in = n_channel,\n",
    "        train_patch_size = trainModelSettings[\"train_patch_size\"],\n",
    "        unet_activation = trainModelSettings[\"unet_activation\"],\n",
    "    )\n",
    "    print(conf)\n",
    "    vars(conf)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 242.84it/s]\n",
      "100%|██████████| 77/77 [00:01<00:00, 66.85it/s]\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/csbdeep/models/base_model.py:134: UserWarning: output path for model already exists, files may be overwritten: /home/trasse/github/OpSeF-IV/Train/TrainStarDist/models/Non_Augmented_Train_Small2\n",
      "  warnings.warn('output path for model already exists, files may be overwritten: %s' % str(self.logdir.resolve()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images:  77\n",
      "- training:        65\n",
      "- validation:      12\n",
      "Config2D(axes='YXC', backbone='unet', grid=(2, 2), n_channel_in=1, n_channel_out=33, n_dim=2, n_rays=32, net_conv_after_unet=128, net_input_shape=(None, None, 1), net_mask_shape=(None, None, 1), train_background_reg=0.0001, train_batch_size=4, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_completion_crop=32, train_dist_loss='mae', train_epochs=400, train_foreground_only=0.9, train_learning_rate=0.0003, train_loss_weights=(1, 0.2), train_n_val_patches=None, train_patch_size=(256, 256), train_reduce_lr={'factor': 0.5, 'patience': 40, 'min_delta': 0}, train_shape_completion=False, train_steps_per_epoch=100, train_tensorboard=True, unet_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_kernel_size=(3, 3), unet_last_activation='relu', unet_n_conv_per_depth=2, unet_n_depth=3, unet_n_filter_base=32, unet_pool=(2, 2), unet_prefix='', use_gpu=False)\n",
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 2.2467 - prob_loss: 0.3614 - dist_loss: 9.4269 - prob_kld: 0.2599 - dist_relevant_mae: 9.4262 - dist_relevant_mse: 154.7263 - val_loss: 1.9020 - val_prob_loss: 0.2527 - val_dist_loss: 8.2468 - val_prob_kld: 0.1671 - val_dist_relevant_mae: 8.2459 - val_dist_relevant_mse: 137.2001\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 1.5754 - prob_loss: 0.2580 - dist_loss: 6.5872 - prob_kld: 0.1542 - dist_relevant_mae: 6.5860 - dist_relevant_mse: 82.0305 - val_loss: 1.5183 - val_prob_loss: 0.1254 - val_dist_loss: 6.9643 - val_prob_kld: 0.0398 - val_dist_relevant_mae: 6.9628 - val_dist_relevant_mse: 95.6669\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 1.3061 - prob_loss: 0.1366 - dist_loss: 5.8477 - prob_kld: 0.0363 - dist_relevant_mae: 5.8466 - dist_relevant_mse: 65.9384 - val_loss: 1.1963 - val_prob_loss: 0.1050 - val_dist_loss: 5.4561 - val_prob_kld: 0.0195 - val_dist_relevant_mae: 5.4554 - val_dist_relevant_mse: 65.3880\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.9651 - prob_loss: 0.1244 - dist_loss: 4.2037 - prob_kld: 0.0231 - dist_relevant_mae: 4.2030 - dist_relevant_mse: 40.6225 - val_loss: 0.8825 - val_prob_loss: 0.1007 - val_dist_loss: 3.9089 - val_prob_kld: 0.0151 - val_dist_relevant_mae: 3.9079 - val_dist_relevant_mse: 36.0063\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NMS threshold = 0.3:  80%|████████  | 16/20 [00:11<00:02,  1.38it/s, 0.475 -> 0.547]\n",
      "NMS threshold = 0.4:  80%|████████  | 16/20 [00:13<00:03,  1.20it/s, 0.476 -> 0.539]\n",
      "NMS threshold = 0.5:  80%|████████  | 16/20 [00:17<00:04,  1.12s/it, 0.482 -> 0.520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimized values: prob_thresh=0.473643, nms_thresh=0.3.\n",
      "Saving to 'thresholds.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 269.86it/s]\n",
      "100%|██████████| 77/77 [00:01<00:00, 64.04it/s]\n",
      "/home/trasse/anaconda3/envs/opsef004/lib/python3.6/site-packages/csbdeep/models/base_model.py:134: UserWarning: output path for model already exists, files may be overwritten: /home/trasse/github/OpSeF-IV/Train/TrainStarDist/models/Non_Augmented_Train_Medium2\n",
      "  warnings.warn('output path for model already exists, files may be overwritten: %s' % str(self.logdir.resolve()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images:  77\n",
      "- training:        65\n",
      "- validation:      12\n",
      "Config2D(axes='YXC', backbone='unet', grid=(2, 2), n_channel_in=1, n_channel_out=33, n_dim=2, n_rays=32, net_conv_after_unet=128, net_input_shape=(None, None, 1), net_mask_shape=(None, None, 1), train_background_reg=0.0001, train_batch_size=4, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_completion_crop=32, train_dist_loss='mae', train_epochs=400, train_foreground_only=0.9, train_learning_rate=0.0003, train_loss_weights=(1, 0.2), train_n_val_patches=None, train_patch_size=(256, 256), train_reduce_lr={'factor': 0.5, 'patience': 40, 'min_delta': 0}, train_shape_completion=False, train_steps_per_epoch=100, train_tensorboard=True, unet_activation='relu', unet_batch_norm=False, unet_dropout=0.0, unet_kernel_size=(3, 3), unet_last_activation='relu', unet_n_conv_per_depth=2, unet_n_depth=3, unet_n_filter_base=32, unet_pool=(2, 2), unet_prefix='', use_gpu=False)\n",
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 2.3202 - prob_loss: 0.3582 - dist_loss: 9.8101 - prob_kld: 0.2564 - dist_relevant_mae: 9.8095 - dist_relevant_mse: 165.6614 - val_loss: 1.6631 - val_prob_loss: 0.2849 - val_dist_loss: 6.8910 - val_prob_kld: 0.1863 - val_dist_relevant_mae: 6.8895 - val_dist_relevant_mse: 79.4776\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 1.5239 - prob_loss: 0.2584 - dist_loss: 6.3276 - prob_kld: 0.1545 - dist_relevant_mae: 6.3264 - dist_relevant_mse: 75.7815 - val_loss: 1.3778 - val_prob_loss: 0.1730 - val_dist_loss: 6.0243 - val_prob_kld: 0.0744 - val_dist_relevant_mae: 6.0230 - val_dist_relevant_mse: 69.3616\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 1.1466 - prob_loss: 0.1428 - dist_loss: 5.0189 - prob_kld: 0.0405 - dist_relevant_mae: 5.0178 - dist_relevant_mse: 51.7078 - val_loss: 1.1552 - val_prob_loss: 0.1248 - val_dist_loss: 5.1520 - val_prob_kld: 0.0262 - val_dist_relevant_mae: 5.1509 - val_dist_relevant_mse: 49.5415\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.8691 - prob_loss: 0.1248 - dist_loss: 3.7211 - prob_kld: 0.0234 - dist_relevant_mae: 3.7202 - dist_relevant_mse: 32.4581 - val_loss: 0.8260 - val_prob_loss: 0.1183 - val_dist_loss: 3.5389 - val_prob_kld: 0.0197 - val_dist_relevant_mae: 3.5381 - val_dist_relevant_mse: 32.0213\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NMS threshold = 0.3:  75%|███████▌  | 15/20 [00:12<00:04,  1.16it/s, 0.487 -> 0.581]\n",
      "NMS threshold = 0.4:  75%|███████▌  | 15/20 [00:15<00:05,  1.01s/it, 0.560 -> 0.562]\n",
      "NMS threshold = 0.5:  75%|███████▌  | 15/20 [00:18<00:06,  1.24s/it, 0.568 -> 0.544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimized values: prob_thresh=0.484394, nms_thresh=0.3.\n",
      "Saving to 'thresholds.json'.\n"
     ]
    }
   ],
   "source": [
    "for trainModelSettings in run_list:\n",
    "    # prepare data\n",
    "    X = sorted(glob('{}/train/images/*.tif'.format(trainModelSettings[\"path\"])))\n",
    "    Y = sorted(glob('{}/train/masks/*.tif'.format(trainModelSettings[\"path\"])))\n",
    "    assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "    \n",
    "    # load data\n",
    "    X = list(map(tif.imread,X))\n",
    "    Y = list(map(tif.imread,Y))\n",
    "    n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    \n",
    "    # Normalize images and fill small label holes\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    # axis_norm = (0,1,2) # normalize channels jointly\n",
    "    if n_channel > 1:\n",
    "        print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "        sys.stdout.flush()\n",
    "    X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "    Y = [fill_label_holes(y) for y in tqdm(Y)]\n",
    "    \n",
    "    # Split into train and validation datasets.\n",
    "    assert len(X) > 1, \"not enough training data\"\n",
    "    rng = np.random.RandomState(42)\n",
    "    ind = rng.permutation(len(X))\n",
    "    n_val = max(1, int(round(0.15 * len(ind))))\n",
    "    ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "    X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "    X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "    print('number of images: %3d' % len(X))\n",
    "    print('- training:       %3d' % len(X_trn))\n",
    "    print('- validation:     %3d' % len(X_val))\n",
    "    \n",
    "    # define setting\n",
    "    conf = config_stardist(trainModelSettings,n_channel)\n",
    "    augmenter = None\n",
    "\n",
    "    # train model\n",
    "    model = StarDist2D(conf, name=trainModelSettings[\"name\"], basedir = trainModelSettings[\"basedir_StarDist_Train\"])\n",
    "    median_size = calculate_extents(list(Y), np.median)\n",
    "    fov = np.array(model._axes_tile_overlap('YX'))\n",
    "    if any(median_size > fov):\n",
    "        print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=trainModelSettings[\"epochs\"] , steps_per_epoch=trainModelSettings[\"steps_per_epoch\"])\n",
    "    model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jkjk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7044d2ca689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjkjk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'jkjk' is not defined"
     ]
    }
   ],
   "source": [
    "jkjk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "A `StarDist2D` model is specified via a `Config2D` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Config2D.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The trained `StarDist2D` model will *not* predict completed shapes for partially visible objects at the image boundary if `train_shape_completion=False` (which is the default option)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We now load images from the sub-folder `test` that have not been used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('{}/test/images/*.tif'.format(trainModelSettings[\"root\"])))\n",
    "X = list(map(tif.imread,X))\n",
    "\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all test images\n",
    "if False:\n",
    "    fig, ax = plt.subplots(7,8, figsize=(16,16))\n",
    "    for i,(a,x) in enumerate(zip(ax.flat, X)):\n",
    "        a.imshow(x if x.ndim==2 else x[...,0], cmap='gray')\n",
    "        a.set_title(i)\n",
    "    [a.axis('off') for a in ax.flat]\n",
    "    plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Make sure to normalize the input image beforehand or supply a `normalizer` to the prediction function.\n",
    "\n",
    "Calling `model.predict_instances` will\n",
    "- predict object probabilities and star-convex polygon distances (see `model.predict` if you want those)\n",
    "- perform non-maximum suppression (with overlap threshold `nms_thresh`) for polygons above object probability threshold `prob_thresh`.\n",
    "- render all remaining polygon instances in a label image\n",
    "- return the label instances image and also the details (coordinates, etc.) of all remaining polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = normalize(X[16], 1,99.8, axis=axis_norm)\n",
    "labels, details = model.predict_instances(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img if img.ndim==2 else img[...,0], clim=(0,1), cmap='gray')\n",
    "plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(model, i, show_dist=True):\n",
    "    img = normalize(X[i], 1,99.8, axis=axis_norm)\n",
    "    labels, details = model.predict_instances(img)\n",
    "\n",
    "    plt.figure(figsize=(13,10))\n",
    "    img_show = img if img.ndim==2 else img[...,0]\n",
    "    coord, points, prob = details['coord'], details['points'], details['prob']\n",
    "    plt.subplot(121); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    a = plt.axis()\n",
    "    _draw_polygons(coord, points, prob, grid=model.config.grid, show_dist=show_dist)\n",
    "    plt.axis(a)\n",
    "    plt.subplot(122); plt.imshow(img_show, cmap='gray'); plt.axis('off')\n",
    "    plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example(model, 15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
