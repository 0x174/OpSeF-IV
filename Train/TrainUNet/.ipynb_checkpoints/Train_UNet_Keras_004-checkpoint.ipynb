{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook based on \"segmentation_example_keras\" and \"solution\" notebooks\n",
    "the EMBL Machine Learning for Image Analysis Course 2018:\n",
    "\n",
    "Organisers \n",
    "Anna Kreshuk - EMBL, Vera Matser - EMBL EBI, Tobias Rasse - EMBL\n",
    "\n",
    "Trainers\n",
    "Thorsten Falk - Freiburg University\n",
    "Fred Hamprecht - Heidelberg University\n",
    "Anna Kreshuk - EMBL\n",
    "Constantin Pape - Heidelberg University\n",
    "Tobias Rasse - EMBL\n",
    "Pejman Rasti - Université d’Angers\n",
    "David Rousseau - Université d’Angers\n",
    "Martin Weigert - MPI-CBG\n",
    "Uwe Schmidt - MPI-CBG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modified by Tobias Rasse tobias.rasse@mpi-bn.mpg.de for use in OpSeF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88c8f888-4eb5-438e-8428-0d6f9280aa70",
    "_uuid": "3cf23599bb2587214d3f8b50d3b512bb025159f1"
   },
   "source": [
    "### Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "# h5py to read the data-set\n",
    "import h5py\n",
    "# matplotlob for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# tensorboard\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import pickle\n",
    "from glob import glob\n",
    "import os\n",
    "from csbdeep.utils import Path, normalize\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available,_draw_polygons\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import skimage.segmentation\n",
    "import skimage.morphology\n",
    "import skimage.transform\n",
    "from scipy.ndimage.morphology import binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_target(label, size_filter=25, boundary_width=2, for_pytorch=True):\n",
    "    # next, label the annotations and remove small objects\n",
    "    label = skimage.morphology.label(label)\n",
    "    label = skimage.morphology.remove_small_objects(label, min_size=size_filter)\n",
    "    # next, find boundaries and dilate them\n",
    "    boundaries = skimage.segmentation.find_boundaries(label)\n",
    "    boundaries = binary_dilation(boundaries, iterations=boundary_width)\n",
    "    # the way we process the labels depends on the framework we are using.\n",
    "    # for pytorch, we need labels with a single channel, where the values stand for:\n",
    "    # 0: background\n",
    "    # 1: inner cells\n",
    "    # 2: cell boundaries\n",
    "    if for_pytorch:\n",
    "        label_out = np.zeros_like(label, dtype='int64')\n",
    "        label_out[(label != 0) & (boundaries == 0)] = 1\n",
    "        label_out[boundaries == 1] = 2\n",
    "    \n",
    "    # for keras we need three binary channels as labels:\n",
    "    # channel 0: background\n",
    "    # channel 1: inner cells\n",
    "    # channel 2: cell boundaries\n",
    "    else:\n",
    "        label_out = np.zeros(label.shape + (3,), dtype='int64')\n",
    "        label_out[(label == 0) & (boundaries == 0), 0] = 1.\n",
    "        label_out[(label != 0) & (boundaries == 0), 1] = 1.\n",
    "        label_out[boundaries == 1, 2] = 1.\n",
    "    return label_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = os.path.dirname(os.path.abspath(inspect.stack()[0][1])).replace(\"TrainUNet\",\"Augment\")\n",
    "file_path = \"{}/my_runs/augment_settings_xl.pkl\".format(main_folder)\n",
    "infile = open(file_path,'rb')\n",
    "parameter = pickle.load(infile)\n",
    "print(\"Loading processing pipeline from\",file_path)\n",
    "infile.close()\n",
    "aug_sets,pre_defined_pipelines,data_main_GT,Datasets_Download = parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training settings\n",
    "trainModelSettings = {}\n",
    "trainModelSettings[\"root\"] = data_main_GT\n",
    "trainModelSettings[\"data\"] = \"DSB2018_FL_Nuc_Subset_Basic_Nuc_512\"\n",
    "trainModelSettings[\"path\"] = os.path.join(trainModelSettings[\"root\"],trainModelSettings[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('{}/train/images/*.tif'.format(trainModelSettings[\"path\"])))\n",
    "Y = sorted(glob('{}/train/masks/*.tif'.format(trainModelSettings[\"path\"])))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y))\n",
    "\n",
    "# load data\n",
    "X = list(map(tif.imread,X))\n",
    "Y = list(map(tif.imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "    \n",
    "# Normalize images and fill small label holes\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse label: \n",
    "Keras needs as input one label per class (e.g. background, boundary, cell).\n",
    "We currently have one label per cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a look at the labels\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(Y[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the data\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X[0][:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \", len(np.unique(Y[0])), \"unique label:\",np.unique(Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert label\n",
    "Y3 = [label_to_target(ll) for ll in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a look at the labels\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(Y3[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y3binary = [to_categorical(img) for img in Y3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 0\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(Y3binary[i][:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Binary 0')\n",
    "\n",
    "plt.subplot(132)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(Y3binary[i][:,:,1])\n",
    "plt.colorbar()\n",
    "plt.title('Binary 1')\n",
    "\n",
    "plt.subplot(133)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(Y3binary[i][:,:,2])\n",
    "#plt.imshow(preds_train[i][:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Binary 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y3 = Y3binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y3 = np.stack([label_to_target(ll) for ll in Y])\n",
    "val_labels = np.stack([label_to_target(ll) for ll in val_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation datasets.\n",
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y3[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y3[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add axis were needed and stack images\n",
    "\n",
    "# train\n",
    "X_trn_arr = np.stack([img[:,:,None] for img in X_trn])\n",
    "print(X_trn_arr.shape)\n",
    "Y_trn_arr = np.stack([img for img in Y_trn])\n",
    "print(Y_trn_arr.shape)\n",
    "\n",
    "# validate\n",
    "X_val_arr = np.stack([img[:,:,None] for img in X_val])\n",
    "print(X_val_arr.shape)\n",
    "Y_val_arr = np.stack([img for img in Y_val])\n",
    "print(Y_val_arr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    eps = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each block of u-net architecture consist of two Convolution layers\n",
    "# These two layers are written in a function to make our code clean\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size=3):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
    "               padding=\"same\")(input_tensor)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), \n",
    "               padding=\"same\")(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The u-net architecture consists of contracting and expansive paths which\n",
    "# shrink and expands the inout image respectivly. \n",
    "# Output image have the same size of input image\n",
    "def get_unet(input_img, n_filters):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*4, kernel_size=3) #The first block of U-net\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*8, kernel_size=3)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*16, kernel_size=3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*32, kernel_size=3)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*64, kernel_size=3)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*32, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*32, kernel_size=3)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*16, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*16, kernel_size=3)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*8, kernel_size=3)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*4, kernel_size=3)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((X_trn_arr.shape[1], X_trn_arr.shape[2], 1), name='img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and Compiling the model\n",
    "#input_img = Input((X_trn[0].shape[1], X_trn[0].shape[2], 1), name='img')\n",
    "model = get_unet(input_img, n_filters=4)\n",
    "\n",
    "#model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[dice_coefficient])\n",
    "#model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=['dice_coefficient'])\n",
    "\n",
    "# use CategoricalCrossentropy if there is more than one class\n",
    "# otherwise BinaryCrossentropy\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the log and show it by tensorboard\n",
    "NAME='u-net'\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiting the model \n",
    "results = model.fit(X_trn_arr, Y_trn_arr, batch_size=1, epochs=10, callbacks=[tensorboard],\n",
    "                    validation_data=(X_val_arr, Y_val_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_trn_arr, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t = (preds_train > 0.3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(X_trn_arr[i][:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Input')\n",
    "\n",
    "plt.subplot(132)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(Y_trn_arr[i][:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Label')\n",
    "\n",
    "plt.subplot(133)  #sublot(Anzahl Zeilen Anzahl Spalten Bild Nummer)\\\n",
    "plt.imshow(preds_train_t[i][:,:,0])\n",
    "#plt.imshow(preds_train[i][:,:,0])\n",
    "plt.colorbar()\n",
    "plt.title('Prediction')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a look at the labels\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(preds_train_t[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a look at the labels\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X_trn_arr[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first have a look at the labels\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(Y3[0][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = np.stack([predict_image(net, im) for im in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainModelSettings[\"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].shape)\n",
    "if len(X[0].shape) == 2:\n",
    "    IMG_HEIGHT, IMG_WIDTH = X[0].shape\n",
    "    IMG_CHANNELS = 1\n",
    "else:\n",
    "    IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(img_list,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,my_datatype,add_axis = False):\n",
    "    # convers list to array\n",
    "    IMG_arr = np.zeros((len(img_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=my_datatype)\n",
    "    for n in range(len(X_val)):\n",
    "        if add_axis:\n",
    "            IMG_arr[n,:,:,0] = img_list[n]\n",
    "        else:\n",
    "            IMG_arr[n,:,:,:] = img_list[n]\n",
    "    return IMG_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from lists to arrays\n",
    "X_trn_arr = to_array(X_trn,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8,True)\n",
    "Y_trn_arr = to_array(Y_trn,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8)\n",
    "X_val_arr = to_array(X_val,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8,True)\n",
    "Y_val_arr = to_array(Y_val,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiting the model \n",
    "results = model.fit(X_trn_arr, Y_trn_arr, batch_size=1, epochs=2, callbacks=[tensorboard],\n",
    "                    validation_data=(X_val_arr, Y_val_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_trn_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    eps = 1e-6\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].shape)\n",
    "if len(X[0].shape) == 2:\n",
    "    IMG_HEIGHT, IMG_WIDTH = X[0].shape\n",
    "    IMG_CHANNELS = 1\n",
    "else:\n",
    "    IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jkjkjk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae011253-08b8-44db-8be9-c1092e171553",
    "_uuid": "17f9af12f2fc93a2e57c3cfdc3c122f97f1fa7e4"
   },
   "source": [
    "###  3. Creating the U-net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d17d35a-753d-47c5-b1d7-7effa1af04a7",
    "_uuid": "a9378262b0194c0aa54df3e2ea5696b447f8ef83"
   },
   "source": [
    "###  4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModelSettings[\"epochs\"] = 2\n",
    "trainModelSettings[\"steps_per_epoch\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(img_list,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,my_datatype,add_axis = False):\n",
    "    # convers list to array\n",
    "    IMG_arr = np.zeros((len(img_list),1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=my_datatype)\n",
    "    for n in range(len(X_val)):\n",
    "        if add_axis:\n",
    "            IMG_arr[n,0,:,:,0] = img_list[n]\n",
    "        else:\n",
    "            IMG_arr[n,0,:,:,:] = img_list[n]\n",
    "    return IMG_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from lists to arrays\n",
    "X_trn_arr = to_array(X_trn,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8,True)\n",
    "Y_trn_arr = to_array(Y_trn,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8)\n",
    "X_val_arr = to_array(X_val,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8,True)\n",
    "Y_val_arr = to_array(Y_val,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS,np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_trn_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a training and validation generator that generate masks and images\n",
    "train_generator = zip(X_trn_arr, Y_trn_arr)\n",
    "val_generator = zip(X_val_arr, Y_val_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go from list to arrays\n",
    "X_val_arr = np.zeros((len(X_val), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=my_datatype)\n",
    "for n in range(len(X_val)):\n",
    "    X_val_arr[n,:,:,0] = X_val[n]\n",
    "Y_val_arr = np.zeros((len(Y_val), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "for n in range(len(X_val)):\n",
    "    Y_val_arr[n,:,:,0] = Y_val[n]  \n",
    "\n",
    "X_val_arr = np.zeros((len(X_val), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "for n in range(len(X_val)):\n",
    "    X_val_arr[n,:,:,0] = X_val[n]\n",
    "Y_val_arr = np.zeros((len(Y_val), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "for n in range(len(X_val)):\n",
    "    Y_val_arr[n,:,:,0] = Y_val[n]   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a training and validation generator that generate masks and images\n",
    "train_generator = zip(X_trn, Y_trn)\n",
    "val_generator = zip(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=100,\n",
    "                              epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cc45263-7607-4d9d-b0e0-88b3135ba60b",
    "_uuid": "440055f1d1feb25fe08f942d15257e2454d2022b"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=3, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=250,\n",
    "                              epochs=3, callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_trn, Y_trn, validation_data=(X_val,Y_val),\n",
    "            epochs=trainModelSettings[\"epochs\"] , steps_per_epoch=trainModelSettings[\"steps_per_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # train model\n",
    "    model = StarDist2D(conf, name=trainModelSettings[\"name\"], basedir = trainModelSettings[\"basedir_StarDist_Train\"])\n",
    "    median_size = calculate_extents(list(Y), np.median)\n",
    "    fov = np.array(model._axes_tile_overlap('YX'))\n",
    "    if any(median_size > fov):\n",
    "        print(\"WARNING: median object size larger than field of view of the neural network.\")\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=trainModelSettings[\"epochs\"] , steps_per_epoch=trainModelSettings[\"steps_per_epoch\"])\n",
    "    model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e12a9f1-279f-4031-b8c5-4f825f84cc13",
    "_uuid": "168a4d55c79c92cd17a398cff13876fb0b32cdbf"
   },
   "source": [
    "###  5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ef72a295-7187-41d6-9ecf-c5ee201f000d",
    "_uuid": "f9b92b3ce2079288fe8a2ed75f3c8679ee93113f"
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbad21c9-d1ef-4aee-9e16-8b340e38cd69",
    "_uuid": "b050929802713d41a75fc97a960ac6534e5cbde1"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c9fed3a-fa91-4957-833f-c2b8adf64743",
    "_uuid": "bf24083f20c4e618eeee2933dc1fd1a36413f8b7"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2e17c4a-e84e-4552-950d-a49e95393ed9",
    "_uuid": "b66a4b8ebd2a804d8d102436b0953183bdb4f30b"
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46ff9859-1d81-4a7b-be2a-f0421a67ad79",
    "_uuid": "b27241fd5a881fa0b17711ed71b7a99b7a9b4859"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
