{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Use with Run_002_dev !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General description of OpSeF\n",
    "\n",
    "The analysis pipeline consists of four principle sets of functions to import and reshape the data, to pre-process it, to segment it and to analyze and classify results.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_M1.jpg\" alt = \"Paper Fig M1\" style = \"width: 500px;\"/>\n",
    "\n",
    "OpSeF is designed such that parameter for pre-processing and selection of the ideal model for segmentation are one functional unit. \n",
    "\n",
    "The first three sets of functions are explained in the OpSeF_IV_Setup_Basic_0001_Skeletal_Muscle Demo Notebook.\n",
    "\n",
    "This notebook illustrates the following post-processing options:\n",
    "\n",
    "- Plot Results\n",
    "- Export to CSV\n",
    "- Cluster Analysis\n",
    "- Export to Fiji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the skeletal muscle dataset\n",
    "\n",
    "A methylen blue stained skeletal muscle was used as test image for nuclear segmentation.\n",
    "To this aim 2048 x 2048 pixel large patches were extracted.\n",
    "\n",
    "Importantly, these patches contain border of multiple images that were stiched together after image aquisition at a slidescanner.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_R5_A.jpg\" alt = \"Paper Fig R5 A\" style = \"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Core-Settings that shall not be changed\n",
    "Please use OpSef_Configure_XXX to change these global settings.\n",
    "Changes in this file only necessary to intergrate new model,\n",
    "or to change the aut-ogenerated folderstructure.\n",
    "Changes to the folderstructure might cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processing pipeline from ./my_runs/main_settings.pkl\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./my_runs/main_settings.pkl\"\n",
    "infile = open(file_path,'rb')\n",
    "parameter = pickle.load(infile)\n",
    "print(\"Loading processing pipeline from\",file_path)\n",
    "infile.close()\n",
    "model_dic,folder_structure = parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define General Parameter\n",
    "most parameter define the overall processing and likeley do not change between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that determine the processing pipeline and (generally) do not change between runs\n",
    "\n",
    "pc = {}\n",
    "\n",
    "#################\n",
    "## Basic ########\n",
    "#################\n",
    "\n",
    "pc[\"sub_f\"] = folder_structure # these folder will be auto-generated\n",
    "pc[\"batch_size\"] = 2 # the number of images to be quantified must be a multiple of batch size (for segmentation)\n",
    "                     # extract the properties (below) from region_props\n",
    "pc[\"get_property\"] = [\"label\",\"area\",\"centroid\", \"eccentricity\", \n",
    "                      \"equivalent_diameter\",\"mean_intensity\",\"max_intensity\",\n",
    "                      \"min_intensity\",\"perimeter\"]\n",
    "pc[\"naming_scheme\"] = \"Simple\"        # or \"Simple\" Export_ZSplit\" to create substacks\n",
    "pc[\"toFiji\"] = True   # Shall images be prepared for import in Fiji \n",
    "\n",
    "###############################\n",
    "# Define use of second channel\n",
    "###############################\n",
    "\n",
    "pc[\"export_another_channel\"] = True  # export other channel (to create a mask or for quantification) ?\n",
    "if [\"export_another_channel\"]:\n",
    "    pc[\"create_filter_mask_from_channel\"] = True # use second channel to make a mask?\n",
    "    pc[\"Quantify_2ndCh\"] = False      # shall this channel be quantified?\n",
    "    if pc[\"Quantify_2ndCh\"]:\n",
    "        pc[\"merge_results\"] = True    # shall the results of the two intensity quantification be merged \n",
    "                                     # (needed for advanced plotting)\n",
    "        pc[\"plot_merged\"] = True     # plot head of dataframe in notebook ?\n",
    "\n",
    "################################\n",
    "# Define Analysis & Plotting ###\n",
    "################################\n",
    "\n",
    "pc[\"Export_to_CSV\"] = True # shall results be exported to CSV (usually only true for the final run)\n",
    "if pc[\"Export_to_CSV\"]:\n",
    "    pc[\"Intensity_Ch\"] = 0 # put 999 if data contains only one channel\n",
    "    pc[\"Plot_Results\"] = True # Do you want to plot results ?\n",
    "    pc[\"Plot_xy\"] = [[\"area\",\"mean_intensity\"],[\"area\",\"circularity\"]] # Define what you want to plot (x/y)\n",
    "    pc[\"plot_head_main\"] = True # plot head of dataframe in notebook ?\n",
    "    pc[\"Do_ClusterAnalysis\"] = True # shall cluster analysis be performed?\n",
    "    if pc[\"Do_ClusterAnalysis\"]: # Define (below) which values will be included in the TSNE:\n",
    "        pc[\"Cluster_How\"] = \"Mask\" # or \"Mask\"\n",
    "        if pc[\"Cluster_How\"] == \"Auto\":\n",
    "            pc[\"cluster_expected\"] = 2 # How many groups/classes do you expected?\n",
    "        pc[\"include_in_tsne\"] = [\"area\",\"eccentricity\",\"equivalent_diameter\",\n",
    "                                 \"mean_intensity\",\"max_intensity\",\"min_intensity\",\"perimeter\"]\n",
    "        pc[\"tSNE_learning_rate\"] = 100 # Define learning rate\n",
    "        pc[\"link_method\"] = \"ward\" # or \"average\", or \"complete\", or \"single\" details see below\n",
    "    else:\n",
    "        pc[\"Cluster_How\"] = \"Not\"\n",
    "else:\n",
    "    pc[\"Plot_Results\"] = False\n",
    "    pc[\"Do_ClusterAnalysis\"] = False\n",
    "    pc[\"Cluster_How\"] = \"Not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here input & basic processing that (generally) does not change between runs\n",
    "\n",
    "input_def = {}\n",
    "input_def[\"root\"] = \"/mnt/ag-microscopy/SampleDataML/SlideScanner_muscle_mask\" # define folder where images are located\n",
    "input_def[\"dataset\"] = \"muscle_mask\" # give the dataset a common name\n",
    "input_def[\"mydtype\"] = np.uint8 # bit depth of input images\n",
    "\n",
    "input_def[\"input_type\"] = \".tif\" # or .tif\n",
    "if input_def[\"input_type\"] == \".tif\":\n",
    "    input_def[\"is3D\"] = False # is the data 3D or 2D ???\n",
    "    if pc[\"export_another_channel\"]:\n",
    "        input_def[\"export_seg_ch\"] = \"Ch_00_\" # give unique string to identify the channel\n",
    "elif input_def[\"input_type\"] == \".lif\":\n",
    "    input_def[\"rigth_size\"] = (2048,2048) \n",
    "    input_def[\"export_single_ch\"] = 99   # which channel to extract from the lif file (99 if only one)\n",
    "\n",
    "input_def[\"split_z\"] = False # chose here to split z-stack into multiple substacts to avoid that cells fuse after projection\n",
    "if input_def[\"split_z\"]:# choosen, define:\n",
    "    input_def[\"z_step\"] = 3 # size of substacks\n",
    "    if input_def[\"input_type\"] == \".lif\":\n",
    "        input_def[\"export_multiple_ch\"] = [0,1] # channels to be exported\n",
    "    \n",
    "\n",
    "#########################################################################\n",
    "## the following options are only implemented with Tiff files as input ##\n",
    "#########################################################################\n",
    "\n",
    "input_def[\"toTiles\"] = False\n",
    "if input_def[\"toTiles\"]:\n",
    "    input_def[\"patch_size\"] = (15,512,512)\n",
    "\n",
    "# run5\n",
    "input_def[\"bin\"] = False\n",
    "if input_def[\"bin\"]:\n",
    "    input_def[\"bin_factor\"] = 2 # same for x/y\n",
    "\n",
    "# coming soon...\n",
    "input_def[\"n2v\"] = False\n",
    "input_def[\"CARE\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter for export (if needed)\n",
    "\n",
    "if pc[\"export_another_channel\"]:\n",
    "    input_def[\"post_export_single_ch\"] = 1                   # which channel to extract from the lif file\n",
    "    input_def[\"post_subset\"] = [\"Ch_01_\"]          # analyse these intensity images if exporting from lif\n",
    "                                                  # use also to search for the right channel if exporting \n",
    "                                                  # from tiff, works only if subset for main channel is \"All\"\n",
    "    if pc[\"Quantify_2ndCh\"]:\n",
    "        pc[\"Intensity_2ndCh\"] = input_def[\"post_export_single_ch\"]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "# in this dictionary all settings for the model are stored\n",
    "initModelSettings = {}\n",
    "# Variables U-Net Cellprofiler\n",
    "initModelSettings[\"UNet_model_file_CP01\"] = \"./model_Unet/UNet_CP001.h5\"\n",
    "initModelSettings[\"UNetShape\"] = (2048,2048) # run1,2\n",
    "initModelSettings[\"UNetShape\"] = (1024,1024) # run 3\n",
    "initModelSettings[\"UNetSettings\"] = [{\"activation\": \"relu\", \"padding\": \"same\"},{ \"momentum\": 0.9}]\n",
    "# Variables StarDist\n",
    "initModelSettings[\"basedir_StarDist\"] = \"./model_stardist\"\n",
    "# Variables Cellpose\n",
    "initModelSettings[\"Cell_Channels\"] = [[0,0],[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Post-Processing\n",
    "\n",
    "Segmented objects can be filtered by their region propperties or a mask, results might be exported to AnnotatorJ and re-imported for further analysis. Blue arrows define the default processing pipeline, grey arrows feature available options. Dark Blue boxes are core components, light blue boxes are optional processing steps.\n",
    "\n",
    "<img src=\"./Figures_Demo/Fig_M5.jpg\" alt = \"Paper Fig M5\" style = \"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define variable that might change in each run\n",
    "\n",
    "run_def = {}\n",
    "run_def[\"display_base\"] = \"000\" # defines the image used as basis for the overlay. See documemtation for details.\n",
    "run_def[\"run_ID\"] = \"000\" #give each run a new ID (unless you want to overwrite the old data)\n",
    "run_def[\"clahe_prm\"] = [(18,18),3] # Parameter for CLAHE\n",
    "\n",
    "# Run 5\n",
    "input_def[\"subset\"] = [\"All\"] # filter by name\n",
    "\n",
    "#########################\n",
    "# Define preprocessing ##\n",
    "#########################\n",
    "\n",
    "run_def[\"pre_list\"] =  [[\"Median\",3,0,\"Max\",False,run_def[\"clahe_prm\"],\"no\",True]] # run 5\n",
    "\n",
    "# For Cellpose\n",
    "run_def[\"rescale_list\"] = [0.6] # run 5\n",
    "\n",
    "# Define model\n",
    "run_def[\"ModelType\"] = [\"CP_nuclei\"] # run 5\n",
    "\n",
    "############################################################\n",
    "# Define postprocessing & filtering                       #\n",
    "# keep only the objects within the defined ranges         #\n",
    "###########################################################\n",
    "\n",
    "# (same for all runs) \n",
    "run_def[\"filter_para\"] = {}\n",
    "run_def[\"filter_para\"][\"area\"] = [0,10000]\n",
    "run_def[\"filter_para\"][\"perimeter\"] = [0,99999999]\n",
    "run_def[\"filter_para\"][\"circularity\"] = [0,1] # (equivalent_diameter * math.pi) / perimeter\n",
    "run_def[\"filter_para\"][\"mean_intensity\"] = [0,65535]\n",
    "run_def[\"filter_para\"][\"sum_intensity\"] = [0,100000000000000]\n",
    "run_def[\"filter_para\"][\"eccentricity\"] = [0,10]\n",
    "\n",
    "############################################################################\n",
    "# settings that are only needed if condition below is met which means you  #\n",
    "# plan to use a mask from a second channel to filter results               #\n",
    "############################################################################\n",
    "\n",
    "if pc[\"create_filter_mask_from_channel\"]:\n",
    "    run_def[\"binary_filter_mp\"] = [[\"open\",5,2,1,\"Morphology\"],[\"close\",5,3,1,\"Morphology\"],[\"erode\",5,1,1,\"Morphology\"]]\n",
    "    run_def[\"para_mp\"] = [[\"Mean\",5],[0.6],run_def[\"binary_filter_mp\"]]\n",
    "    run_def[\"Use User Mask\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to reproduce these results?\n",
    "\n",
    "The notebook is set up to reproduce the results of the last run (Run 4)\n",
    "\n",
    "The execute previous runs please delete or commented out settings used for Run 4 \n",
    "\n",
    "Settings are saved in a .pkl file.\n",
    "\n",
    "The next cell prints the filepath & name of this file.\n",
    "\n",
    "OpSef_Run_XXX loads the settings specified above and processed all images.\n",
    "The only change you have to make within OpSef_Run_XXX  is specifying the location\n",
    "of this setting file.\n",
    "\n",
    "## Save Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please execute this file with OPsef_Run_XXX ./Demo_Notebooks/my_runs/Parameter_muscle_mask_Run_000.pkl\n"
     ]
    }
   ],
   "source": [
    "#  auto-create parameter set from input above\n",
    "run_def[\"run_now_list\"] = [model_dic[x] for x in run_def[\"ModelType\"]]\n",
    "parameter = [pc,input_def,run_def,initModelSettings]\n",
    "\n",
    "# save it\n",
    "file_name = \"./my_runs/Parameter_{}_Run_{}.pkl\".format(input_def[\"dataset\"],run_def[\"run_ID\"])\n",
    "file_name_load = \"./Demo_Notebooks/my_runs/Parameter_{}_Run_{}.pkl\".format(input_def[\"dataset\"],run_def[\"run_ID\"])\n",
    "print(\"Please execute this file with OPsef_Run_XXX\",file_name_load)\n",
    "outfile = open(file_name,'wb')\n",
    "pickle.dump(parameter,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## Folderstructure    ####\n",
    "\n",
    "input_def[\"root\"] = \"/home/trasse/OpSefDemo/leaves\" # defines the main folder \n",
    "\n",
    "# Put files in these subfolder\n",
    "# .lif\n",
    "# root/myimage_container.lif\n",
    "# root/tiff/myimage1.tif (in case this folder is the direct input to the pre-processing pipeline)\n",
    "#          /myimage2.tif ...\n",
    "# or\n",
    "# root/tiff_raw_2D/myimage1.tif (if you want to make patches in 2D)\n",
    "# root/tiff_to_split/myimage1.tif (if you want ONLY create substacts, bt not BIN or patch before)\n",
    "# root/tiff_raw/myimage1.tif (for all pipelines that start with patching or binning and use stacks)\n",
    "\n",
    "\n",
    "######################################\n",
    "### What is a display base image ????\n",
    "######################################\n",
    "\n",
    "run_def[\"display_base\"]\n",
    "''' \n",
    "display base is ideally set to \"same\".\n",
    "in this case the visualiation of segmentation border will be\n",
    "drawn on top of the input image to the segmentation\n",
    "If this behavior is not desired a three digit number\n",
    "that refers to the position in the run_def[\"pre_list\"] might to be entered.\n",
    "example:\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,8,\"Sum\",True,clahe_prm],[\"Mean\",5,3,\"Max\",True,clahe_prm]]\n",
    "& the image resulting from:\n",
    "[\"Mean\",5,3,\"Max\",True,clahe_prm]\n",
    "shall be used as basis for display:\n",
    "then set: \n",
    "run_def[\"display_base\"] = \"001\"\n",
    "'''\n",
    "\n",
    "##########################\n",
    "# Parameter for Cellpose:\n",
    "##########################\n",
    "\n",
    "# Define: \n",
    "# initModelSettings[\"Cell_Channels\"] \n",
    "# to run segementation on grayscale=0, R=1, G=2, B=3\n",
    "# initModelSettings[\"Cell_Channels\"] = [cytoplasm, nucleus]\n",
    "# if NUCLEUS channel does not exist, set the second channel to 0\n",
    "initModelSettings[\"Cell_Channels\"] = [[0,0],[0,0]]\n",
    "\n",
    "# IF ALL YOUR IMAGES ARE THE SAME TYPE, you can give a list with 2 elements\n",
    "initModelSettings[\"Cell_Channels\"] = [0,0] # IF YOU HAVE GRAYSCALE\n",
    "initModelSettings[\"Cell_Channels\"] = [2,3] # IF YOU HAVE G=cytoplasm and B=nucleus\n",
    "initModelSettings[\"Cell_Channels\"] = [2,1] # IF YOU HAVE G=cytoplasm and R=nucleus\n",
    "\n",
    "# if rescale is set to None, the size of the cells is estimated on a per image basis\n",
    "# if you want to set the size yourself, set it to 30. / average_cell_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "## Variables for Preprocessing\n",
    "#####################################\n",
    "\n",
    "## The list \n",
    "\n",
    "run_def[\"pre_list\"]\n",
    "\n",
    "#is organized as such:\n",
    "\n",
    "# (1) Filter type\n",
    "# (2) Kernel\n",
    "# (3) substract fixed value\n",
    "# (4) projection type\n",
    "# (5) calhe enhance (Yes/No) as defined above\n",
    "# (6) Calhe parameter\n",
    "# (7) enhance edges (and how) (no, roberts, sobel)\n",
    "# (8) invert image\n",
    "\n",
    "# It is a list of lists, each entry defines one pre-processing pipeline:\n",
    "\n",
    "# e.g.\n",
    "# Run1\n",
    "run_def[\"pre_list\"] = [[\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",True,run_def[\"clahe_prm\"],\"no\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"sobel\",False],\n",
    "                       [\"Median\",3,50,\"Max\",False,run_def[\"clahe_prm\"],\"no\",True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link analysis (Settings from t-SNE)\n",
    "\n",
    "from https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "linkage{“ward”, “complete”, “average”, “single”}\n",
    "\n",
    "Which linkage criterion to use:\n",
    "\n",
    "The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.\n",
    "\n",
    "ward minimizes the variance of the clusters being merged. average uses the average of the distances of each observation of the two sets. complete or maximum linkage uses the maximum distances between all observations of the two sets.\n",
    "\n",
    "single uses the minimum of the distances between all observations of the two sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
